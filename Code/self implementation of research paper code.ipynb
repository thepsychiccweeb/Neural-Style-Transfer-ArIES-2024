{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 \n",
    "import PIL\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG19(include_top=True, weights=\"imagenet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    gram_matrix = tf.expand_dims(result, axis=0)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    i_j = tf.cast(input_shape[1], input_shape[2], tf.float32) \n",
    "    return gram_matrix/i_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg():\n",
    "    vgg = tf.keras.applications.VGG19(include_top= True, weights=None)\n",
    "    vgg.load_weights('C:/Users/prajw/Downloads/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    vgg.trainable = False\n",
    "    content_layers = ['block4_conv2']\n",
    "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "    content_output = vgg.get_layer(content_layers[0]).output\n",
    "    style_output = [vgg.get_layer(style_layer).output for style_layer in style_layers]\n",
    "    gram_style_output = [gram_matrix(output_) for output in style_output]\n",
    "\n",
    "    model = Model([vgg.input], [content_output, gram_style_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "content_image = cv2.resize(cv2.imread('C:/Users/prajw/Downloads/image-from-rawpixel-id-3282175-jpeg (1).jpg'), (256,256))\n",
    "content_image = tf.image.convert_image_dtype(content_image, tf.float32)\n",
    "style_image = cv2.resize(cv2.imread('C:/Users/prajw/Downloads/image-from-rawpixel-id-537438-jpeg (1).jpg'), (256,256))\n",
    "style_image = tf.image.convert_image_dtype(style_image, tf.float32)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.cvtColor(np.array(content_image), cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.cvtColor(np.array(style_image), cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate = 0.01, beta_1=0.99, epsilon=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_object(style_outputs, content_outputs, style_target, content_target):\n",
    "    style_weight = 0.01\n",
    "    content_weight = 0.1\n",
    "    content_loss = tf.reduce_mean((content_outputs - content_target)**2)\n",
    "    style_loss = tf.add_n(tf.reduce_mean((output_ - target_)**2) for output_,target_ in zip(style_outputs,style_target))\n",
    "    total_loss = content_weight*content_loss + style_weight*style_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = load_vgg()\n",
    "content_target = vgg_model(np.array([content_image * 255]))[0]\n",
    "style_target = vgg_model(np.array([style_image * 255]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(image, epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output = vgg_model(image*255)\n",
    "        loss = loss_object(output[1], output[2], style_target, content_target)\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    opt.apply_gradients[((gradient, image))]\n",
    "    image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0))\n",
    "\n",
    "    if epoch%10 == 0:\n",
    "        tf.print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "image = tf.image.convert_image_dtype(content_image, tf.float32)\n",
    "image = tf.Variable([image])\n",
    "for i in range(EPOCHS):\n",
    "    train_step(image,i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "tensor = image*255\n",
    "tensor = np.array(tensor, dtype=np.unit8)\n",
    "if np.ndim(tensor)>3:\n",
    "    assert tensor.shape[0] == 1\n",
    "    tensor = tensor[0]\n",
    "\n",
    "tensor = PIL.Image.fromarray(tensor)\n",
    "plt.imshow(cv2.cvtColor(np.array(tensor), cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
